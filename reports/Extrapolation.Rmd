---
title: "Extrapolating Capacity Estimates to a Linear Stream Network"
author:
  - name: Kevin See
    affiliation: biomark
    email: kevin.see@merck.com
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  bookdown::pdf_document2:
    pandoc_args:
    - --lua-filter=templates/scholarly-metadata.lua
    - --lua-filter=templates/author-info-blocks2.lua
    - --lua-filter=templates/pagebreak.lua
    fig_height: 8
    fig_width: 6
    number_sections: no
    includes:
      in_header: "templates/header_ABS.tex"
  bookdown::html_document2:
    theme: simplex
    toc: yes
    toc_depth: 3
    toc_float: yes
    fig_height: 8
    fig_width: 8
    number_sections: no
    pandoc_args:
    - --lua-filter=templates/scholarly-metadata.lua
    - --lua-filter=templates/author-info-blocks.lua
    - --lua-filter=templates/pagebreak.lua
  bookdown::word_document2: 
    fig_caption: yes
    fig_height: 7
    fig_width: 6
    toc: yes
    number_sections: no
    pandoc_args:
    - --lua-filter=templates/scholarly-metadata.lua
    - --lua-filter=templates/author-info-blocks.lua
    - --lua-filter=templates/pagebreak.lua
    reference_docx: "templates/ReportTemplate.docx"
institute:
- biomark: Biomark, Inc.
csl: "templates/american-fisheries-society.csl"
# bibliography: references.bib
bibliography: 
  - references.bib
  - packages.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# setwd('reports')
# load knitr for markdown
library(knitr)
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE,
                      # error = FALSE,
                      message=FALSE)
#options(tinytex.verbose = TRUE)
options(knitr.kable.NA = '-')
# options(knitr.table.format = "pandoc")

library(kableExtra)
```

```{r}
# load needed packages
library(tidyverse)
library(sf)
library(QRFcapacity)
library(janitor)
library(ggpubr)
library(ggrepel)
library(scales)

theme_set(theme_bw())
```

```{r package-bibtex, eval = F}
knitr::write_bib(c("base",
                   "survey", 
                   "sf", 
                   "knitr", 
                   "rmarkdown"),
                 file = 'packages.bib')
```

```{r lifestage, eval = F}
# which QRF model to use?
mod_choice = c('juv_summer',
               'juv_summer_dash',
               'redds')[2]
```

```{r reach-capacity, eval = F}
# read in capacity estimates and create a shapefile
load(paste0('../output/modelFits/extrap_200rch_', mod_choice, '.rda'))
in_covar_range_rch = model_svy_df$pred_all_rchs[[1]] %>%
  select(UniqueID, in_covar_range)
rch_covars = extrap_covars

mod_rch = model_svy_df %>%
  filter(Species == 'Chinook',
         response == 'cap_per_m') %>%
  mutate(type = "Reaches") %>%
  select(Species,
         response,
         type,
         mod_champ,
         mod_no_champ) %>%
  pivot_longer(cols = starts_with("mod"),
               names_to = "version",
               values_to = "model") %>%
  mutate(tidy_summ = map(model,
                         broom::tidy))

data("chnk_domain")
data("rch_200")

rch_200_cap = rch_200 %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         chnk, chnk_use, chnk_ESU_DPS:chnk_NWR_NAME,
         sthd, sthd_use, sthd_ESU_DPS:sthd_NWR_NAME) %>%
  left_join(all_preds %>%
              select(-HUC8_code)) %>%
  mutate(chnk_tot = chnk_per_m * reach_leng,
         chnk_tot_se = chnk_per_m_se * reach_leng) %>%
  mutate(sthd_tot = sthd_per_m * reach_leng,
         sthd_tot_se = sthd_per_m_se * reach_leng) %>%
  mutate_at(vars(starts_with("chnk_tot")),
            list(~ if_else(!chnk, NA_real_, .))) %>%
  mutate_at(vars(starts_with("sthd_tot")),
            list(~ if_else(!sthd, NA_real_, .))) %>%
  # focus on andromous ranges
  filter(chnk | sthd) %>%
  left_join(in_covar_range_rch) %>%
  st_transform(st_crs(chnk_domain)) %>%
  select(everything(), geometry)

rch_200_cap %<>%
  mutate(model_choice = mod_choice) %>%
  select(model_choice, everything())

rm(mod_data_weights, model_svy_df, extrap_covars, rch_200, all_preds)
```

```{r reach-cap-all-models}
all_rch_preds = c('juv_summer',
                  'juv_summer_dash',
                  'redds') %>%
  as.list() %>%
  map_df(.f = function(x) {
    load(paste0('../output/modelFits/extrap_200rch_', x, '.rda'))
    all_preds %>%
      mutate(model_choice = x) %>%
      select(model_choice, everything())
  })

in_covar_range_rch = c('juv_summer',
                       'juv_summer_dash',
                       'redds') %>%
  as.list() %>%
  map_df(.f = function(x) {
    load(paste0('../output/modelFits/extrap_200rch_', x, '.rda'))
    model_svy_df$pred_all_rchs[[1]] %>%
      select(UniqueID, in_covar_range) %>%
      mutate(model_choice = x) %>%
      select(model_choice, everything())
  })

data("chnk_domain")
data("rch_200")

rch_200_cap = rch_200 %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         chnk, chnk_use, chnk_ESU_DPS:chnk_NWR_NAME,
         sthd, sthd_use, sthd_ESU_DPS:sthd_NWR_NAME) %>%
  left_join(all_rch_preds %>%
              select(-HUC8_code)) %>%
  mutate_at(vars(chnk_ESU_DPS:chnk_NWR_NAME, sthd_ESU_DPS:sthd_NWR_NAME),
            list(fct_explicit_na)) %>%
  mutate(chnk_tot = chnk_per_m * reach_leng,
         chnk_tot_se = chnk_per_m_se * reach_leng) %>%
  mutate(sthd_tot = sthd_per_m * reach_leng,
         sthd_tot_se = sthd_per_m_se * reach_leng) %>%
  mutate_at(vars(starts_with("chnk_tot")),
            list(~ if_else(!chnk, NA_real_, .))) %>%
  mutate_at(vars(starts_with("sthd_tot")),
            list(~ if_else(!sthd, NA_real_, .))) %>%
  # focus on andromous ranges
  filter(chnk | sthd) %>%
  left_join(in_covar_range_rch) %>%
  st_transform(st_crs(chnk_domain)) %>%
  select(everything(), geometry)

# rm(mod_data_weights, model_svy_df, extrap_covars, rch_200, all_preds)

```


```{r master-point-capacity, eval = F}
# read in capacity estimates and create a shapefile
load(paste0('../output/modelFits/extrap_mastPts_', mod_choice, '.rda'))
in_covar_range_pts = model_svy_df$pred_all_rchs[[1]] %>%
  select(Site, in_covar_range)
pts_covars = extrap_covars

mod_pts = model_svy_df %>%
  # filter(Species == 'Chinook',
  #        response == 'cap_per_m') %>%
  mutate(type = "Points") %>%
  select(Species,
         response,
         type,
         mod_champ,
         mod_no_champ) %>%
  pivot_longer(cols = starts_with("mod"),
               names_to = "version",
               values_to = "model") %>%
  mutate(tidy_summ = map(model,
                         broom::tidy))

data("chnk_domain")
data("gaa")

master_pts_cap = gaa %>%
  select(Site, GNIS_Name = GNIS_NA, 
         HUC6_code = HUC_6,
         HUC6_name = HUC6NmNRCS,
         HUC8_code = HUC_8,
         Lat, Lon) %>%
  filter(!is.na(Lon), !is.na(Lat)) %>%
  st_as_sf(coords = c('Lon', 'Lat'),
           crs = 4326) %>%
  st_transform(crs = st_crs(chnk_domain)) %>%
  inner_join(all_preds)

# nhdplus_100 <- st_read("~/Desktop/Flowline_PN17_NSI/Flowline_PN17_NSI.shp") %>%
#   st_transform(st_crs(chnk_domain))

# # this takes longer than 14 hours to run
# test = master_pts_cap %>%
#   st_join(nhdplus_100 %>%
#             select(COMID,
#                    GNIS_ID, 
#                    GNIS_NAME,
#                    reach_leng = LENGTHKM,
#                    reach_code = REACHCODE),
#           join = st_is_within_distance,
#           dist = 200) %>%
#   mutate_at(vars(reach_leng),
#             list(~ . *1000))

# re-define speceies domains to match 200m reaches
chnk_domain = rch_200 %>%
  filter(chnk) %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         starts_with("chnk"))

chnk_buff = chnk_domain %>%
  st_buffer(dist = 200,
            endCapStyle = 'FLAT')

# filter out points outside Chinook domain
keep_rows = master_pts_cap %>%
  st_covered_by(chnk_buff) %>%
  as_tibble() %>%
  pull(row.id) %>%
  unique() %>%
  sort()

chnk_pts_cap = master_pts_cap %>%
  slice(keep_rows) %>%
  st_join(chnk_domain %>%
            select(-one_of(names(master_pts_cap))),
          join = st_nearest_feature)

rm(keep_rows)

chnk_strm_lng = chnk_domain %>%
  mutate(length_m = st_length(.)) %>%
  mutate_at(vars(chnk_ESU_DPS, chnk_NWR_POPID, chnk_NWR_NAME, chnk_MPG, GNIS_Name),
            list(fct_explicit_na)) %>%
  group_by(chnk_ESU_DPS, chnk_MPG, chnk_NWR_POPID, chnk_NWR_NAME, GNIS_Name) %>%
  summarise_at(vars(length_m, reach_leng),
               list(sum))

chnk_strm_cap = chnk_strm_lng %>%
  full_join(chnk_pts_cap %>%
              mutate_at(vars(chnk_ESU_DPS, chnk_NWR_POPID, chnk_NWR_NAME, chnk_MPG, GNIS_Name),
                        list(fct_explicit_na)) %>%
              group_by(chnk_ESU_DPS, chnk_MPG, chnk_NWR_POPID, chnk_NWR_NAME, GNIS_Name) %>%
              summarise_at(vars(chnk_per_m,
                                chnk_per_m_se),
                           list(mean),
                           na.rm = T) %>%
              st_drop_geometry() %>%
              as_tibble()) %>%
  mutate(chnk_tot = chnk_per_m * length_m,
         chnk_tot_se = chnk_per_m_se * length_m)

chnk_strm_cap %<>%
  mutate(model_choice = mod_choice) %>%
  select(model_choice, everything())

sthd_domain = rch_200 %>%
  filter(sthd) %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         starts_with("sthd"))

sthd_buff = sthd_domain %>%
  st_buffer(dist = 200,
            endCapStyle = 'FLAT')

# filter out points outside Chinook domain
keep_rows = master_pts_cap %>%
  st_covered_by(sthd_buff) %>%
  as_tibble() %>%
  pull(row.id) %>%
  unique() %>%
  sort()

sthd_pts_cap = master_pts_cap %>%
  slice(keep_rows) %>%
  st_join(sthd_domain %>%
            select(-one_of(names(master_pts_cap))),
          join = st_nearest_feature)
rm(keep_rows)

sthd_strm_lng = sthd_domain %>%
  mutate(length_m = st_length(.)) %>%
  mutate_at(vars(sthd_ESU_DPS, sthd_NWR_POPID, sthd_NWR_NAME, sthd_MPG, GNIS_Name),
            list(fct_explicit_na)) %>%
  group_by(sthd_ESU_DPS, sthd_MPG, sthd_NWR_POPID, sthd_NWR_NAME, GNIS_Name) %>%
  summarise_at(vars(length_m, reach_leng),
               list(sum))

sthd_strm_cap = sthd_strm_lng %>%
  full_join(sthd_pts_cap %>%
              mutate_at(vars(sthd_ESU_DPS, sthd_NWR_POPID, sthd_NWR_NAME, sthd_MPG, GNIS_Name),
                        list(fct_explicit_na)) %>%
              group_by(sthd_ESU_DPS, sthd_MPG, sthd_NWR_POPID, sthd_NWR_NAME, GNIS_Name) %>%
              summarise_at(vars(sthd_per_m,
                                sthd_per_m_se),
                           list(mean),
                           na.rm = T) %>%
              st_drop_geometry() %>%
              as_tibble()) %>%
  mutate(sthd_tot = sthd_per_m * length_m,
         sthd_tot_se = sthd_per_m_se * length_m)

sthd_strm_cap %<>%
  mutate(model_choice = mod_choice) %>%
  select(model_choice, everything())

rm(mod_data_weights, model_svy_df, extrap_covars, gaa, all_preds)
```

```{r master-point-cap-all-models}
all_pts_preds = c('juv_summer',
              'juv_summer_dash',
              'redds') %>%
  as.list() %>%
  map_df(.f = function(x) {
    load(paste0('../output/modelFits/extrap_mastPts_', x, '.rda'))
    all_preds %>%
      mutate(model_choice = x) %>%
      select(model_choice, everything())
  })

data("chnk_domain")
data("gaa")

master_pts = gaa %>%
  select(Site, GNIS_Name = GNIS_NA, 
         HUC6_code = HUC_6,
         HUC6_name = HUC6NmNRCS,
         HUC8_code = HUC_8,
         Lat, Lon) %>%
  filter(!is.na(Lon), !is.na(Lat)) %>%
  st_as_sf(coords = c('Lon', 'Lat'),
           crs = 4326) %>%
  st_transform(crs = st_crs(chnk_domain))

# re-define speceies domains to match 200m reaches

# Chinook
chnk_domain = rch_200 %>%
  filter(chnk) %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         starts_with("chnk"))

chnk_buff = chnk_domain %>%
  st_buffer(dist = 200,
            endCapStyle = 'FLAT')

# filter out points outside Chinook domain
keep_rows = master_pts %>%
  st_covered_by(chnk_buff) %>%
  as_tibble() %>%
  pull(row.id) %>%
  unique() %>%
  sort()

chnk_pts_cap = master_pts %>%
  slice(keep_rows) %>%
  st_join(chnk_domain %>%
            select(-one_of(names(master_pts))),
          join = st_nearest_feature) %>%
  left_join(all_pts_preds)

rm(keep_rows)

chnk_strm_lng = chnk_domain %>%
  mutate(length_m = st_length(.)) %>%
  mutate_at(vars(chnk_ESU_DPS, chnk_NWR_POPID, chnk_NWR_NAME, chnk_MPG, GNIS_Name),
            list(fct_explicit_na)) %>%
  group_by(chnk_ESU_DPS, chnk_MPG, chnk_NWR_POPID, chnk_NWR_NAME, GNIS_Name) %>%
  summarise_at(vars(length_m, reach_leng),
               list(sum))

chnk_strm_cap = chnk_strm_lng %>%
  full_join(chnk_pts_cap %>%
              mutate_at(vars(chnk_ESU_DPS, chnk_NWR_POPID, chnk_NWR_NAME, chnk_MPG, GNIS_Name),
                        list(fct_explicit_na)) %>%
              group_by(model_choice, chnk_ESU_DPS, chnk_MPG, chnk_NWR_POPID, chnk_NWR_NAME, GNIS_Name) %>%
              summarise(n_pts = n_distinct(Site),
                        chnk_per_m = mean(chnk_per_m, na.rm = T),
                        chnk_per_m_se = mean(chnk_per_m_se, na.rm = T)) %>%
              # summarise_at(vars(chnk_per_m,
              #                   chnk_per_m_se),
              #              list(mean),
              #              na.rm = T) %>%
              st_drop_geometry() %>%
              as_tibble()) %>%
  mutate(chnk_tot = chnk_per_m * length_m,
         chnk_tot_se = chnk_per_m_se * length_m)

# steelhead
sthd_domain = rch_200 %>%
  filter(sthd) %>%
  select(UniqueID, GNIS_Name, reach_leng:HUC8_code, 
         starts_with("sthd"))

sthd_buff = sthd_domain %>%
  st_buffer(dist = 200,
            endCapStyle = 'FLAT')

# filter out points outside Chinook domain
keep_rows = master_pts %>%
  st_covered_by(sthd_buff) %>%
  as_tibble() %>%
  pull(row.id) %>%
  unique() %>%
  sort()

sthd_pts_cap = master_pts %>%
  slice(keep_rows) %>%
  st_join(sthd_domain %>%
            select(-one_of(names(master_pts))),
          join = st_nearest_feature) %>%
  left_join(all_pts_preds)
rm(keep_rows)

sthd_strm_lng = sthd_domain %>%
  mutate(length_m = st_length(.)) %>%
  mutate_at(vars(sthd_ESU_DPS, sthd_NWR_POPID, sthd_NWR_NAME, sthd_MPG, GNIS_Name),
            list(fct_explicit_na)) %>%
  group_by(sthd_ESU_DPS, sthd_MPG, sthd_NWR_POPID, sthd_NWR_NAME, GNIS_Name) %>%
  summarise_at(vars(length_m, reach_leng),
               list(sum))

sthd_strm_cap = sthd_strm_lng %>%
  full_join(sthd_pts_cap %>%
              mutate_at(vars(sthd_ESU_DPS, sthd_NWR_POPID, sthd_NWR_NAME, sthd_MPG, GNIS_Name),
                        list(fct_explicit_na)) %>%
              group_by(model_choice, sthd_ESU_DPS, sthd_MPG, sthd_NWR_POPID, sthd_NWR_NAME, GNIS_Name) %>%
              summarise(n_pts = n_distinct(Site),
                        sthd_per_m = mean(sthd_per_m, na.rm = T),
                        sthd_per_m_se = mean(sthd_per_m_se, na.rm = T)) %>%
              # summarise_at(vars(sthd_per_m,
              #                   sthd_per_m_se),
              #              list(mean),
              #              na.rm = T) %>%
              st_drop_geometry() %>%
              as_tibble()) %>%
  mutate(sthd_tot = sthd_per_m * length_m,
         sthd_tot_se = sthd_per_m_se * length_m)

rm(mod_data_weights, model_svy_df, extrap_covars, gaa, all_preds)

```


```{r create-figures}

comp_pop = chnk_strm_cap %>%
  group_by(model_choice,
           ESU_DPS = chnk_ESU_DPS, 
           MPG = chnk_MPG, 
           NWR_POPID = chnk_NWR_POPID, 
           NWR_NAME = chnk_NWR_NAME) %>%
  summarise(reach_leng = sum(reach_leng, na.rm = T),
            n_ids = sum(n_pts, na.rm = T),
            cap_tot = sum(chnk_tot, na.rm = T),
            cap_tot_se = sqrt(sum(chnk_tot_se^2, na.rm = T))) %>%
  st_drop_geometry() %>%
  as_tibble() %>%
  mutate(Method = 'Points') %>%
  bind_rows(rch_200_cap %>%
              filter(chnk) %>%
              group_by(model_choice,
                       ESU_DPS = chnk_ESU_DPS, 
                       MPG = chnk_MPG, 
                       NWR_POPID = chnk_NWR_POPID, 
                       NWR_NAME = chnk_NWR_NAME) %>%
              summarise(reach_leng = sum(reach_leng),
                        n_ids = n_distinct(UniqueID),
                        cap_tot = sum(chnk_tot, na.rm = T),
                        cap_tot_se = sqrt(sum(chnk_tot_se^2, na.rm = T))) %>%
              st_drop_geometry() %>%
              as_tibble() %>%
              mutate(Method = 'Reaches')) %>%
  mutate(Species = "Chinook") %>%
  select(Species, everything()) %>%
  bind_rows(sthd_strm_cap %>%
              group_by(model_choice,
                       ESU_DPS = sthd_ESU_DPS, 
                       MPG = sthd_MPG, 
                       NWR_POPID = sthd_NWR_POPID, 
                       NWR_NAME = sthd_NWR_NAME) %>%
              summarise(reach_leng = sum(reach_leng, na.rm = T),
                        n_ids = sum(n_pts, na.rm = T),
                        cap_tot = sum(sthd_tot, na.rm = T),
                        cap_tot_se = sqrt(sum(sthd_tot_se^2, na.rm = T))) %>%
              st_drop_geometry() %>%
              as_tibble() %>%
              mutate(Method = 'Points') %>%
              bind_rows(rch_200_cap %>%
                          filter(sthd) %>%
                          group_by(model_choice,
                                   ESU_DPS = sthd_ESU_DPS, 
                                   MPG = sthd_MPG, 
                                   NWR_POPID = sthd_NWR_POPID, 
                                   NWR_NAME = sthd_NWR_NAME) %>%
                          summarise(reach_leng = sum(reach_leng),
                                    n_ids = n_distinct(UniqueID),
                                    cap_tot = sum(sthd_tot, na.rm = T),
                                    cap_tot_se = sqrt(sum(sthd_tot_se^2, na.rm = T))) %>%
                          st_drop_geometry() %>%
                          as_tibble() %>%
                          mutate(Method = 'Reaches')) %>%
              mutate(Species = "Steelhead") %>%
              select(Species, everything()))

# remove a few points that aren't useful
comp_pop %<>%
  filter(NWR_NAME != "na") %>%
  filter(NWR_NAME != "(Missing)") %>%
  filter(!grepl("Outside legal", ESU_DPS)) %>%
  mutate(cap_dens = cap_tot / reach_leng) %>%
  filter(cap_dens < 21) %>%
  mutate(pop_label = str_split(NWR_NAME, " - ", simplify = T)[,2],
         pop_label = str_remove(pop_label, " River"))

pts_rch_cor = comp_pop %>%
  pivot_wider(id_cols = c(Species, 
                          model_choice,
                          ESU_DPS:NWR_NAME),
              names_from = "Method",
              values_from = c("reach_leng", "n_ids", "cap_tot", "cap_tot_se")) %>%
  filter(cap_tot_Points > 0,
         cap_tot_Reaches > 0) %>%
  group_by(Species, model_choice) %>%
  nest() %>%
  mutate(corr = map(data,
                    .f = function(x) {
                      x %>%
                        select(cap_tot_Points, cap_tot_Reaches) %>%
                        corrr::correlate(method = 'pearson')
                    })) %>%
  summarise(corr = map_dbl(corr,
                           .f = function(x) {
                             x[1,3] %>%
                               as.numeric()
                             }))

cap_xy_p = comp_pop %>%
  mutate(model_choice = recode(model_choice,
                               'juv_summer' = 'CHaMP',
                               'juv_summer_dash' = 'DASH',
                               'redds' = 'Redds')) %>%
  pivot_wider(id_cols = c(Species, 
                          model_choice,
                          ESU_DPS:NWR_NAME,
                          pop_label),
              names_from = "Method",
              values_from = c("reach_leng", "cap_tot", "cap_tot_se")) %>%
  # filter(reach_leng > 0)
  filter(cap_tot_Points > 0,
         cap_tot_Reaches > 0) %>%
  ggplot(aes(x = cap_tot_Points/10000,
             y = cap_tot_Reaches/10000,
             color = MPG)) +
  # scale_color_brewer(palette = "Set1",
  #                    name = 'MPG',
  #                    guide = guide_legend(nrow = 3)) +
  geom_abline(linetype = 2) +
  geom_point(size = 4) +
  # geom_label_repel(aes(label = pop_label),
  #                  size = 3,
  #                  fill = 'gray80',
  #                  show.legend = F) +
  theme_classic() +
  theme(legend.position = "bottom") +
  facet_wrap(~ model_choice + Species,
             ncol = 2,
             scales = 'free') +
  labs(x = "Master Sample Points (x10,000)",
       y = "200 m Reaches (x10,000)",
       title = "Capacity")

rel_diff_p = comp_pop %>%
  mutate(model_choice = recode(model_choice,
                               'juv_summer' = 'CHaMP',
                               'juv_summer_dash' = 'DASH',
                               'redds' = 'Redds')) %>%
  mutate_at(vars(ESU_DPS:NWR_NAME, pop_label),
            list(as.factor)) %>%
  mutate(pop_label = fct_reorder(pop_label,
                                 MPG,
                                 .fun = function(x) median(as.integer(x)))) %>%
  pivot_wider(id_cols = c(Species, 
                          model_choice,
                          ESU_DPS:NWR_NAME,
                          pop_label),
              names_from = "Method",
              values_from = c("reach_leng", "cap_tot", "cap_tot_se")) %>%
  filter(cap_tot_Points > 0,
         cap_tot_Reaches > 0) %>%
  mutate(diff = cap_tot_Reaches - cap_tot_Points,
         rel_diff = diff / cap_tot_Points) %>%
  ggplot(aes(x = pop_label,
             y = rel_diff,
             color = MPG)) +
  geom_hline(yintercept = 0,
             linetype = 2) +
  geom_point(size = 4) +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45,
                                   hjust = 1)) +
  # facet_wrap(~ Species, 
  #            scales = 'free_x') +
  facet_grid(model_choice ~ Species,
             scales = 'free_x') +
  labs(x = "Population",
       y = "Relative Difference",
       title = "Capacity")

```



# Introduction

For several years, our development of a QRF capacity model has relied on extrapolation to master sample points to interpolate between CHaMP ([Columbia Habitat Monitoring Program](https://www.champmonitoring.org/)) sites and generate capacity estimates on larger spatial scales. Recently there has been interest in moving from a point-based prediction layer to a line-based prediction layer to aide with the interpretation and visualization of the capacity predictions. In this document, we present our method for doing so, and include some comparisons with the point-based estimates. 

# Methods

## Master Sample Points

The master sample points were generated in the design phase of CHaMP. These 551,046 sites were selected from the NHD Plus 1:100,000 stream layer covering WA, OR and ID at an average density of one site per kilometer [@Larsen2016]. Each CHaMP site where direct QRF capacity estimates were made corresponds to one of these master sample points. CHaMP generated a number o of attributes for each master sample point, referred to here as globally available attributes (GAAs) because they are associated with every master sample point across all watersheds. 

The original extrapolation model used the log of capacity estimates at each CHaMP site (fish / m) as the response, and various GAAs as covariates. The model was fit using the *svyglm* function in the *survey* [@survey2004] package with R software [@R-base], accounting for the various survey design weights within each CHaMP watershed. We then used that model to predict capacity at every master sample point that was not a CHaMP site. To roll up capacity estimates to larger spatial scales, the average predicted capacity of master sample points along a stream was multiplied by the length of that stream, and then combinations of streams could be added together to generate overall capacity estimates for a watershed. 

```{r pts-covars, eval = F}
coef_pts = mod_pts %>%
  select(-model) %>%
  unnest(cols = tidy_summ) %>%
  select(Species:estimate, p.value) %>%
  pivot_wider(names_from = "version",
              values_from = c("estimate", 
                              "p.value")) %>%
  filter(!is.na(estimate_mod_champ),
         !is.na(estimate_mod_no_champ))

sig_cutoff = 0.05

coef_pts %>%
  mutate_at(vars(starts_with("estimate")),
            list(round),
            digits = 3) %>%
  mutate(estimate_mod_champ = cell_spec(estimate_mod_champ,
                                        format = "html",
                                        bold = if_else(p.value_mod_champ < sig_cutoff, T, F)),
         estimate_mod_no_champ = cell_spec(estimate_mod_no_champ,
                                           format = "html",
                                           bold = if_else(p.value_mod_no_champ < sig_cutoff, T, F))) %>%
  select(Species,
         Term = term,
         CHaMP_model = estimate_mod_champ,
         nonCHaMP_model = estimate_mod_no_champ) %>%
  kable(caption = 'Covariates used in master sample point extrapolation models (including CHaMP watershed as a covariate, or not). Those deemed statistically significant are in bold.',
        # digits = 3,
        escape = F,
        booktabs = T) %>%
  kable_styling()
```

## Line Network

We adapted this method to using a [stream layer](https://www.nwfsc.noaa.gov/research/datatech/data/col_basin_hist_project/index.cfm) created by Morgan Bond and Tyler Nodine at the Northwest Fisheries Science Center. This layer consisted of a line file divided into 200m reaches with various attributes attached to each reach. The line file is based on the [National Hydrography Dataset High Resolution](https://www.usgs.gov/core-science-systems/ngp/national-hydrography/nhdplus-high-resolution) (NHDPlus HR) dataset, which has a higher resolution, 1:24,000, compared to the older layer that the master sample points were chosen from. 

We determined which reach was closest to each CHaMP site, and then followed a similar process as described above to model the log of predicted capacity using the attributes attached to each 200m reach as covariates. 

```{r rch-covars, eval = F}
coef_rch = mod_rch %>%
  select(-model) %>%
  unnest(cols = tidy_summ) %>%
  select(Species:estimate, p.value) %>%
  pivot_wider(names_from = "version",
              values_from = c("estimate", 
                              "p.value")) %>%
  filter(!is.na(estimate_mod_champ),
         !is.na(estimate_mod_no_champ))

sig_cutoff = 0.05

coef_rch %>%
  mutate_at(vars(starts_with("estimate")),
            list(round),
            digits = 3) %>%
  mutate(estimate_mod_champ = cell_spec(estimate_mod_champ,
                                        format = "html",
                                        bold = if_else(p.value_mod_champ < sig_cutoff, T, F)),
         estimate_mod_no_champ = cell_spec(estimate_mod_no_champ,
                                           format = "html",
                                           bold = if_else(p.value_mod_no_champ < sig_cutoff, T, F))) %>%
  select(Species,
         Term = term,
         CHaMP_model = estimate_mod_champ,
         nonCHaMP_model = estimate_mod_no_champ) %>%
  kable(caption = 'Covariates used in 200 m reach extrapolation models (including CHaMP watershed as a covariate, or not). Those deemed statistically significant are in bold.',
        # digits = 3,
        escape = F,
        booktabs = T) %>%
  kable_styling()
```

# Capacity Comparisons

We computed the total capacity of each species in each population using both methods, for summer juveniles (using both CHaMP and DASH habitat metrics) and redds, and compared them. A handful of populations with extrememly inflated estimates were left out. The correlations between the two estimates are shown in Table \@ref(tab:corr-tab). 

<!-- We could go back and fix any extrapolation estimate that is too high to be the max observed density, or the max predicted density at a CHaMP site. This might help shrink some of the extreme values -->

```{r corr-tab}
pts_rch_cor %>%
  mutate(model_choice = recode(model_choice,
                               'juv_summer' = 'CHaMP',
                               'juv_summer_dash' = 'DASH',
                               'redds' = 'Redds')) %>%
  rename(r = corr) %>%
  kable(booktabs = T,
        digits = 3,
        caption = "Correlation coefficient between capacity estimates at the population scale using each method.") %>%
  kable_styling()
```

We plotted one estimate against the other in Figure \@ref(fig:comp-xy), and showed the relative difference in Figure \@ref(fig:comp-rel).

```{r comp-xy, fig.cap = "Capacity estimates for each population, calculated with the master sample points method on the x-axis and the line network on the y-axis."}
cap_xy_p +
  guides(color = guide_legend(ncol = 3))

```

```{r comp-rel, fig.height = 7, fig.cap = "Relative difference between the capacity estimates for each population, using the master sample points method as the reference."}
rel_diff_p +
  guides(color = guide_legend(ncol = 3)) +
  theme(axis.text.x = element_text(size = 5))
```

# Maps

This shows the difference in how the results can be visualized.

```{r lem-map, fig.cap='Plots of Chinook parr capacity in the Lemhi, using the master sample points method (A) and the 200 m reach method (B).'}
lem_rch = rch_200_cap %>%
  filter(model_choice == 'juv_summer_dash') %>%
  filter(grepl('Lemhi', chnk_NWR_NAME)) %>%
  filter(chnk) %>%
  ggplot(aes(color = chnk_per_m2)) +
  geom_sf(size = 1.5) +
  scale_color_viridis_c(direction = -1,
                        name = expression("Parr /" ~ m^2))

lem_pts = chnk_pts_cap %>%
  filter(model_choice == 'juv_summer_dash') %>%
  filter(grepl('Lemhi', chnk_NWR_NAME)) %>%
  ggplot(aes(color = chnk_per_m2)) +
  geom_sf() +
  scale_color_viridis_c(direction = -1,
                        name = expression("Parr /" ~ m^2))

ggarrange(plotlist = list(lem_pts, lem_rch),
          nrow = 1,
          labels = 'AUTO',
          common.legend = T,
          legend = 'bottom')


```

# Discussion

For both species, across all three QRF models, the two extrapolation models resulted in very similar estimates of total capacity at the population scale. Although the master sample point method has been used for several years, there is no reason to believe estimates from that method are inherently superior to using a line network, so even in the cases when the two models result in different estimates of capacity, it is difficult to say which is "better". On the other hand, there are several reasons to support using the line network method, apart from the actual results.

# References
