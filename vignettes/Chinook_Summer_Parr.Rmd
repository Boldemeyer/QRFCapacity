---
title: "Chinook Summer Parr"
author: "Kevin See^[Biomark Inc.]"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    fig_height: 8
    fig_width: 8
    toc: yes
    toc_depth: 1
vignette: >
  %\VignetteIndexEntry{Chinook_Summer_Parr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
csl: /Users/kevin/Dropbox/Bibliography/StyleFiles/ecology.csl
bibliography:
- /Users/kevin/Dropbox/Bibliography/Research.bib
- /Users/kevin/Dropbox/Bibliography/SoftwareCitations.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(knitr)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)

library(pander)
# options for table formatting
panderOptions('big.mark', ',')
# panderOptions('digits', 3)
# panderOptions('round', 3)
panderOptions('keep.trailing.zeros', FALSE)
panderOptions('table.split.table', Inf)

library(captioner)
tab_nums = captioner(prefix = 'Table')
fig_nums = captioner()


# load packages for analysis
library(QRFcapacity)
library(tidyverse)
library(magrittr)
library(minerva)
library(sf)
library(quantregForest)

# set default theme for ggplot
theme_set(theme_bw())
```

```{r}
# determine which set of fish/habitat data to use, and which species to focus on
data(fh_sum_champ_2014)

fish_hab = fh_sum_champ_2014 %>%
  filter(Species == 'Chinook') %>%
  mutate_at(vars(Watershed, Year),
            list(as.factor))
```


# Introduction

# Data

The fish data was collected by various agencies during the summer low-flow season at many of the same sites surveyed using the CHaMP protocol. Survey methods included mark-recapture, three-pass removal sampling, two-pass removal sampling, and single-pass electrofishing, as well as snorkeling. We estimated juvenile fish abundance (and density) at all sites where fish survey data were available. Three-pass removal estimates used the Carle-Strub estimator (@Carle1978), following advice from @Hedger2013. Two-pass removal estimates used the estimator described by @Seber2002. Mark-recapture estimates used Chapmanâ€™s modified Lincoln-Peterson estimator (@Chapman1951) and were deemed valid if they met the criteria described in @Robson1964. These estimates were made using the `removal` and `mrClosed` functions from the FSA package (@Ogle2017) in R software (@Rsoftware2015). Snorkel counts were transformed to abundance estimates using paired snorkel-electrofishing sites to calibrate snorkel counts. 

Many sites were sampled in multiple years. To avoid any chance of pseudo-replication (since habitat data is not usually expected to vary much year-to-year), for any site with multiple surveys, we chose the survey with the highest estimated density. We used this criteria because we are interested in estimating carrying capacity, so using the highest observed density seemed appropriate.

***All sites fell within the range of steelhead, but many of them were outside the range of spring/summer Chinook salmon. However, defining the range of sp/su Chinook is tricky, and it is unclear if the reported data for Chinook salmon includes only sites considered with the range of Chinook, or if we should exclude data from some sites based on our best understanding of the species' range. Currently, we are using all data.***

```{r, eval = F}
library(maptools)

data(chnk_domain)
spp_domain = chnk_domain

# which sites were sampled for fish? 
fish_samps = fish_hab %>%
  select(Site:Lon) %>%
  distinct() %>%
  st_as_sf(coords = c('Lon', 'Lat'),
           crs = 4326) %>%
  st_transform(st_crs(spp_domain))

# set snap distance (in meters)
st_crs(fish_samps)
snap_dist = 1000

# which of those sites are in the fish's domain?
fish_sites = fish_samps %>%
  as_Spatial() %>%
  maptools::snapPointsToLines(spp_domain %>%
                                mutate(id = 1:n()) %>%
                                select(id, MPG) %>%
                                as_Spatial(),
                              maxDist = snap_dist,
                              withAttrs = T,
                              idField = 'id') %>%
  as('sf')

fish_hab %<>%
  filter(Site %in% fish_sites$Site |
           Watershed == 'John Day')
```

After matching up the fish abundances with sites where we have habitat data, we are left with the following number of sites.

```{r}

fish_hab %>%
  xtabs(~ Watershed + Year, .) %>%
  addmargins() %>%
  pander()
```

# Selecting Covariates

A key step in developing a QRF model to predict fish capacities is selecting the habitat covariates to include in the model. Random forest models naturally incorporate interactions between correlated covariates, which is essential since nearly all habitat variables are considered correlated to one degree or another. However, we aimed to avoid overly redundant variables (i.e., variables that measure similar aspects of the habitat). Further, including too many covariates can result in overfitting of the model (e.g., including as many covariates as data points).

## Methods

We used the Maximal Information-Based Nonparametric Exploration (MINE) class of statistics (@Reshef2011) to determine those habitat characteristics (covariates) most highly associated with observed parr densities. We calculated the maximal information coefficient (MIC), using the R package `minerva` (@Albanese2013), to measure the strength of the linear or non-linear association between two variables (@Reshef2011). The MIC value between each of the measured habitat characteristics and the response variable, juvenile fish density (fish/m), was used to inform decisions on which habitat covariates to include in the QRF parr capacity model.
	Habitat metrics were first grouped into broad categories that included channel unit, complexity, cover, disturbance, riparian, size, substrate, temperature, water quality, and woody debris. Within each category, metrics were ranked according to their MIC value (Figure 1). Our strategy was to select one or two variables with the highest MIC score within each category so that covariates describe different aspects of rearing habitat (e.g., substrate, temperature, etc.). 

```{r MINE_stats}
data(hab_dict_2014)


# unique(hab_dict$MetricCategory[hab_dict$MetricCategory != 'Categorical']) %>%
#   str_replace('WaterQuality', 'Water Quality') %>%
#   str_replace('ChannelUnit', 'Channel Unit') %>%
#   str_to_lower() %>%
#   sort() %>%
#   paste(collapse = ', ')

# what are some possible habitat covariates?
poss_hab_mets = hab_dict_2014 %>%
  filter(MetricCategory != 'Categorical') %>%
  filter(ShortName %in% names(fish_hab)) %>%
  pull(ShortName)

mine_res = fish_hab %>%
  mutate(fish_dens = log(fish_dens + 0.005)) %>%
  estimate_MIC(covars = poss_hab_mets,
               response = 'fish_dens') %>%
  left_join(hab_dict %>%
              select(Metric = ShortName,
                     MetricCategory,
                     Name),
            by = 'Metric') %>%
  # put the metric names in descending order by MIC
  mutate_at(vars(Metric, Name),
            list(~ fct_reorder(., .x = MIC))) %>%
  select(Species, MetricCategory, Metric, everything()) %>%
  arrange(Species, MetricCategory, desc(MIC))

mine_plot_df = mine_res #%>%
  # filter out some metrics with too many NAs or 0s
  # filter((perc_NA < 0.2 & non_0 > 100) | MetricCategory == 'Temperature') %>%
  # # filter out metrics with very low variance
  # filter(var < 0.1) %>% select(1:11)
  # # filter out area and volume metrics
  # filter(!grepl('Area', Metric),
  #        !grepl('Vol', Metric),
  #        Metric != 'Lgth_Wet')
```

## Results

```{r mine_plot}
# make a plot of MIC values for all species
mine_p = mine_plot_df %>%
  ggplot(aes(x = Name,
             y = MIC,
             fill = Species)) +
  geom_col(position = position_dodge(1)) +
  coord_flip() +
  facet_wrap(~ MetricCategory,
             scales = 'free_y',
             ncol = 3) +
  scale_fill_brewer(palette = 'Set1',
                    guide = guide_legend(nrow = 1)) +
  theme(legend.position = 'bottom',
        axis.text = element_text(size = 5))

mine_p

```

```{r}
mine_p2 = mine_plot_df %>%
  ggplot(aes(x = Name,
             y = MIC,
             fill = Species)) +
  geom_col(position = position_dodge(1)) +
  coord_flip() +
  scale_fill_brewer(palette = 'Set1',
                    guide = guide_legend(nrow = 1)) +
  theme(legend.position = 'bottom',
        axis.text = element_text(size = 5))

mine_p2
```

In the end, we decided to use the same metrics for both species, and chose the following metrics:

```{r}
sel_hab_mets = c('CU_Freq',
                 'DpthThlwg_UF_CV',
                 'WetWDRat_Avg',
                 'FishCovTotal',
                 'DistPrin1',
                 'RipCovGrnd',
                 'DpthThlwg_Avg',
                 'SubEstGrvl',
                 'SubD50',
                 'SubLT6',
                 'AvgHourly',
                 'Max7dAM',
                 'Cond',
                 'LWFreq_Wet')

```

```{r hab_mets_correlation}
library(corrr)
#----------------------------------------------
# Look at correlations between habitat metrics
#----------------------------------------------

corr_mat = avgHab_v2 %>%
  select(one_of(sel_hab_mets)) %>%
  corrr::correlate()

corr_mat %>%
  rearrange(absolute = F) %>%
  shave(upper = T) %>% 
  stretch() %>%
  filter(!is.na(r)) %>%
  arrange(desc(abs(r)))
  filter(abs(r) > 0.5)

corr_mat %>%
  rearrange(absolute = F) %>%
  shave(upper = T) %>% 
  rplot(legend = T,
        print_cor = T)

network_plot(corr_mat)
  
```

# Fit QRF Models

## Methods

Random forest models cannot handle missing data by default, so the first step is to impute any missing data. In order to limit the amount of imputation necessary, we first delete any observation with too many missing values, and then impute the rest. 

```{r impute_qrf_data}
qrf_data = impute_missing_data(data = fish_hab,
                               covars = sel_hab_mets,
                               impute_vars = c('Watershed', 'Elev_M', 'Sin', 'Year', 'CUMDRAINAG'),
                               method = 'missForest') %>%
      select(Site, Watershed, Year, LON_DD, LAT_DD, fish_dens, VisitID, one_of(sel_hab_mets))

# log transform the response
# set the density offset (to accommodate 0s)
dens_offset = 0.005

qrf_data %<>%
  mutate_at(vars(fish_dens),
            list(~ log(. + dens_offset)))
```

```{r fit_qrf_model}
set.seed(3) 
qrf_mod = quantregForest(x = qrf_data %>%
                           select(one_of(sel_hab_mets)) %>%
                           as.matrix,
                         y = qrf_data %>%
                           select(fish_dens) %>%
                           as.matrix(),
                         keep.inbag = T,
                         ntree = 1000)
```

## Results

We can examine the relative importance of each covariate. These importance values are calculated on the average prediction of the random forest, not an upper quantile. However, metrics that are important for predicting the average should also be important for predicting upper quantiles, as part of the relative importance calculation is how sensitive the random forest predictions are to changes in that metric.

```{r relative_importance plot}

rel_imp_p = qrf_mod$importance %>%
  as_tibble(rownames = 'Metric') %>%
  mutate(relImp = IncNodePurity / max(IncNodePurity)) %>%
  left_join(hab_dict_2014 %>%
              select(Metric = ShortName,
                     Name) %>%
              distinct()) %>%
  mutate_at(vars(Metric, Name),
            list(~ fct_reorder(., relImp))) %>%
  arrange(Metric) %>%
  ggplot(aes(x = Name,
             y = relImp)) +
  geom_col(fill = 'gray40') +
  coord_flip() +
  labs(x = 'Metric',
       y = 'Relative Importance')

rel_imp_p
```

We can also examine partial dependence plots for each metric. A partial depedence plot shows how the predicted response changes as the value of one covariate shifts over its range, while all the other covariates remain at their average values. In reality, because there is usually some correlation between our habitat covariates, if one covariate shifts then others often do to, which would effect the predictions. However, these plots can be thought of as the marginal effect of each covariate. They are a good way to gain some intuition for the fish / habitat relationships the model is estimating.

```{r partial_dep_plots}
pdp_p = plot_partial_dependence(qrf_mod,
                                qrf_data,
                                data_dict = hab_dict_2014)
pdp_p
```


# Predict at Habitat Sites

## Methods

```{r}
qrf_preds = impute_missing_data(data = champ_site_2011_14 %>%
                                  filter(VisitObjective == 'Primary Visit',
                                         VisitStatus == 'Released to Public') %>%
                                  mutate_at(vars(VisitYear),
                                            list(as.factor)),
                                covars = sel_hab_mets,
                                impute_vars = c('Elev_M', 'Sin', 'VisitYear', 'CUMDRAINAG'),
                                method = 'Hmisc') %>%
  select(Site, Watershed, Year = VisitYear, LON_DD, LAT_DD, VisitID, one_of(sel_hab_mets)) %>%
  mutate_at(vars(Year),
            list(as.character)) %>%
  bind_rows(impute_missing_data(data = champ_site_2011_14_avg,
                                covars = sel_hab_mets,
                                impute_vars = c('Elev_M', 'Sin', 'CUMDRAINAG'),
                                method = 'Hmisc') %>%
  select(Site, Watershed, Year = VisitYear, LON_DD, LAT_DD, one_of(sel_hab_mets)))

qrf_preds %<>%  
    mutate(qrf_cap = predict(qrf_mod,
                           newdata = qrf_preds %>%
                             select(one_of(rownames(qrf_mod$importance))),
                           what = 0.9)) %>%
  mutate_at(vars(qrf_cap),
            list(~ exp(.) - dens_offset))

```


## Results

```{r}
wtsd = 'Lemhi'
wtsd = 'Upper Grande Ronde'
wtsd = 'Wenatchee'
wtsd = 'South Fork Salmon'

qrf_preds %>%
  filter(Year == 'All',
         Watershed == wtsd) %>%
  filter(!is.na(LON_DD)) %>%
  st_as_sf(coords = c('LON_DD', 'LAT_DD'),
           crs = 4326) %>%
  st_transform(5070) %>%
  ggplot() +
  geom_sf(aes(color = qrf_cap)) +
  scale_color_viridis_c(direction = -1) +
  theme_bw() +
  theme(axis.text = element_blank()) +
  labs(title = wtsd,
       color = 'Capacity')

```


# Extrapolation to Other Sites

## Methods

## Results

# References