# Author: Kevin See
# Purpose: Prep habitat data
# Created: 5/14/2019
# Last Modified: 10/28/19
# Notes: some data downloaded from CHaMP webpage on 9/16/2015
# final champ dataset downloaded on 3/8/2018

#-----------------------------------------------------------------
# load needed libraries
library(tidyverse)
library(lubridate)
library(magrittr)
library(WriteXLS)
library(readxl)
library(QRFcapacity)

#-----------------------------------------------------------------
# get globally available attributes from all master sample points
#-----------------------------------------------------------------
gaa = read_csv('data/raw/master_sample_pts/IC_Sites_withMetrics_20151016.csv') %>%
  rename(Site = Site_ID, 
         Lon = LON_DD,
         Lat = LAT_DD) %>%
  # fix one issue with Beechie classification (hardly any "braided" channels)
  mutate(ChanlType = recode(ChanlType,
                            'braided' = 'island_braided')) %>%
  # mark some crazy values as NAs
  mutate_at(vars(GDD, MAVELV, Elev_M, TRange, Precip), 
            list(~ if_else(. < 0, as.numeric(NA), .))) %>%
  mutate_at(vars(Slp_NHD_v1), 
            list(~ if_else(. > 2, as.numeric(NA), .))) %>%
  mutate_at(vars(Site, CHaMPsheds),
            list(as.factor))

# make available like a package, by calling "data()"
use_data(gaa,
         version = 2,
         overwrite = T)

#------------------------------------
# pull out lats/longs for use below
#------------------------------------
data("gaa")

gaa_locs = gaa %>%
  select(Site, Lon, Lat)

gaa_meta = readxl::read_excel('data/raw/master_sample_pts/GAA_Metadata_20150506.xlsx') %>%
  select(ShortName = GlossaryTermName,
         Name = DisplayName,
         DescriptiveText = Description,
         FieldName,
         UnitOfMeasureAbbrv = Units) %>%
  mutate(ShortName = str_remove(ShortName, '_TB$'))

#-----------------------------------------------------------------
# get CHaMP data from 2011 - 2014
#-----------------------------------------------------------------
champ_site_2011_14 = read_csv('data/raw/habitat/CHaMP_ProgramMetrics_20150916/MetricAndCovariates.csv') %>%
  inner_join(read_csv('data/raw/habitat/CHaMP_ProgramMetrics_20150916/MetricVisitInformation.csv')) %>%
  left_join(read_csv('data/raw/habitat/CHaMP_ProgramMetrics_20150916/StreamTempSummer7dAM.csv')) %>%
  mutate_at(vars(SiteName, WatershedName), 
            list(as.factor)) %>%
  arrange(SiteName, VisitYear, SampleDate) %>%
  mutate_at(vars(PoolToTurbulentAreaRatio, BraidChannelRatio), 
            list(as.numeric)) %>%
  # add one more metric related to cnt and freq of channel units
  mutate(CU_Ct = SlowWater_Ct + FstTurb_Ct + FstNT_Ct,
         CU_Freq = CU_Ct / (SiteLength / 100)) %>%
  # add some temperature metrics generated by Kris McNyset's temperature modeling
  left_join(read_csv('data/raw/temperature/kris_temp_pts_mn_mxmn.csv') %>%
              select(SiteName,
                     WatershedName = WatershedN,
                     VisitYear = year,
                     MeanTemp = Mean,
                     MaxMeanTemp = MaxMean))

# get any missing lat/longs from GAA data
champ_site_2011_14 %<>%
  left_join(gaa_locs %>%
              rename(SiteName = Site)) %>%
  mutate(LON_DD = if_else(is.na(LON_DD), Lon, LON_DD),
         LAT_DD = if_else(is.na(LAT_DD), Lat, LAT_DD)) %>%
  select(-Lon, -Lat)


# average metrics across years for sites visited multiple times, keep metrics that don't change
champ_site_2011_14_avg = champ_site_2011_14 %>%
  filter(`Primary Visit` == 'Yes') %>%
  select(-matches('FileName'),
         -matches('GCD')) %>%
  group_by(SiteName) %>%
  summarise_at(vars(SiteLength:WidthCategory,
                    Grad:MaxMeanTemp),
               list(median),
               na.rm = T) %>%
  left_join(champ_site_2011_14 %>%
              filter(`Primary Visit` == 'Yes') %>%
              select(ProgramSiteID:WatershedName,
                     x_albers:Elev_M,
                     OwnerType:MeanU) %>%
              gather(metric, value, -SiteName) %>%
              filter(!is.na(value)) %>%
              distinct() %>%
              spread(metric, value, fill = NA) %>%
              distinct() %>%
              mutate_at(vars(CUMDRAINAG:DistPrin1,
                             Elev_M:LAT_DD,
                             LON_DD:MeanU,
                             NatPrin1:NatPrin2,
                             Ppt:Strah,
                             WatershedID,
                             x_albers:y_albers,
                             CEC_L1, CEC_L2),
                        list(as.numeric))) %>%
  select(one_of(names(champ_site_2011_14)))

# read in dictionary of habitat metrics
hab_dict_2014 = read_csv(paste0('data/raw/habitat/CHaMP_ProgramMetrics_20150916/Definitions.csv'))

# put metrics in categories
hab_catg = filter(hab_dict_2014,
                  MetricGroupName %in% c('Visit Metric', 'Stream Temp Summer 7dAM'),
                  !grepl('^GCD', ShortName),
                  !grepl('GeoDatabase$', ShortName),
                  !grepl('Img$', ShortName),
                  !grepl('^HydraModel', ShortName),
                  !grepl('RBT Outputs', ShortName),
                  !grepl('ResultsXML', ShortName),
                  !grepl('LogFile', ShortName)) %>%
  select(ShortName, Name, DescriptiveText, UnitOfMeasure, UnitOfMeasureAbbrv) %>%
  mutate(MetricCategory = ifelse(grepl('^Sub', ShortName), 'Substrate',
                                 ifelse(grepl('^LW', ShortName), 'Wood',
                                        ifelse((grepl('^FishCov', ShortName) |
                                                  grepl('Ucut', ShortName)), 'Cover',
                                               ifelse(grepl('^RipCov', ShortName), 'Riparian',
                                                      ifelse((grepl('SlowWater', ShortName) |
                                                                grepl('FstTurb', ShortName) |
                                                                grepl('FstNT', ShortName) |
                                                                grepl('PoolToTurbulentAreaRatio', ShortName)), 'ChannelUnit',
                                                             ifelse((grepl('Island', ShortName) |
                                                                       grepl('Sin', ShortName) |
                                                                       grepl('_CV$', ShortName) |
                                                                       grepl('DpthWet_SD', ShortName) |
                                                                       grepl('DetrendElev_SD', ShortName) |
                                                                       grepl('Braid', ShortName) |
                                                                       grepl('Side Channel', Name) |
                                                                       grepl('Lgth_ThlwgCLRat', ShortName) |
                                                                       grepl('DRat', ShortName)), 'Complexity',
                                                                    ifelse((grepl('temperature', DescriptiveText) |
                                                                              grepl('SolarSummr_Avg', ShortName) |
                                                                              grepl('7dAM', ShortName)), 'Temperature',
                                                                           ifelse((grepl('Cond', ShortName) |
                                                                                     grepl('Alk', ShortName) |
                                                                                     grepl('DriftBioMass', ShortName)), 'WaterQuality', 'Size'))))))))) %>%
  mutate(ShortName = as.factor(ShortName),
         MetricCategory = as.factor(MetricCategory))

hab_dict_2014 %<>%
  left_join(hab_catg) %>%
  # add a couple other metrics
  bind_rows(tibble(ShortName = c('DistPrin1', 'NatPrin1', 'NatPrin2', 'mean_JulAug_temp', 'CUMDRAINAG', 'BraidChannelRatio', 'PoolToTurbulentAreaRatio'),
                   Name = c('Disturbance Index', 'Natural PC 1', 'Natural PC 2', 'Mean Summer Temperature', 'Cummulative Drainage Area', 'Braid to Channel Ratio', 'Pool To Turbulent Area Ratio'),
                   DescriptiveText = c('Disturbance index that includes measures of % urban, % agricultural, % impervious surface and road density (Whittier et al. 2011).',
                                       'A natural index that describes watershed slope, precipitation, growing season (growing degree day), and low-gradient streams (Whittier et al. 2011).',
                                       NA,
                                       'Average of all hourly temperature measurements collected July 15 - August 31.',
                                       'The cumulative land area that drains a given location/site.',
                                       NA, NA),
                   UnitOfMeasure = NA,
                   UnitOfMeasureAbbrv = NA,
                   MetricGroupName = c(rep('GAA', 3), 'Visit Metric', 'GAA', rep('Visit Metric', 2)),
                   MetricCategory = c(rep('Land Classification', 3), 'Temperature', 'Size', 'Complexity', 'ChannelUnit'))) %>%
  bind_rows(tibble(ShortName = c('VisitYear', 'ValleyClass', 'ChannelType', 'Ppt', 'MeanU', 'SiteLength', 'AverageBFWidth'),
                   Name = c('Year', 'Valley Class', 'Beechie Channel Type', 'Precipitation', 'Mean Annual Discharge', 'Site Length', 'Average Bankfull Width'),
                   DescriptiveText = NA,
                   UnitOfMeasure = NA,
                   UnitOfMeasureAbbrv = NA,
                   MetricGroupName = c('Visit Metric', rep('GAA', 6)),
                   MetricCategory = c(rep('Categorical', 3), rep('Size', 4)))) %>%
  bind_rows(tibble(ShortName = c('CU_Ct', 'CU_Freq', 'MeanTemp', 'MaxMeanTemp'),
                   Name = c('Channel Unit Count', 'Channel Unit Frequency', 'Mean Summer Temperature', 'Max Mean Weekly Summer Temperature'),
                   UnitOfMeasure = c('Count', 'count per 100 meter', 'Degree (Celsius)', 'Degree (Celsius)'),
                   DescriptiveText = c('Number of channel units.',
                                       'Number of channel units per 100 meters.',
                                       rep(NA, 2)),
                   MetricGroupName = 'Visit Metric',
                   MetricCategory = rep(c('ChannelUnit', 'Temperature'), each = 2))) %>%
  # filter(!is.na(MetricCategory))
  select(ShortName, Name, MetricEngineName, MetricGroupName, DescriptiveText, UnitOfMeasure, UnitOfMeasureAbbrv, MetricCategory) %>%
  distinct()

hab_dict_2014 = hab_dict_2014 %>%
  filter(!ShortName %in% gaa_meta$ShortName) %>%
  bind_rows(hab_dict_2014 %>%
              filter(is.na(MetricEngineName)) %>%
              select(ShortName, MetricCategory) %>%
              inner_join(gaa_meta))

#-----------------------------------------------------------------
# save prepped data
#-----------------------------------------------------------------
list('CHaMP' = champ_site_2011_14,
     'Avg CHaMP' = champ_site_2011_14_avg,
     'Metric Dictionary' = hab_dict_2014) %>%
  WriteXLS('data/Prepped/CHaMP_2011_2014_Data.xlsx',
           AdjWidth = T,
           FreezeRow = 1,
           BoldHeaderRow = T)

# make available like a package, by calling "data()"
use_data(champ_site_2011_14, champ_site_2011_14_avg, hab_dict_2014,
         version = 2,
         overwrite = T)


#-----------------------------------------------------------------
# make use of final CHaMP data - downloaded 3/8/2018
#-----------------------------------------------------------------
load('data/raw/habitat/CHaMP_FinalMetrics_20180308/CHaMPdata.rda')

champ_site_2011_17 = siteData %<>%
  # add one more metric related to cnt and freq of channel units
  mutate(CU_Ct = SlowWater_Ct + FstTurb_Ct + FstNT_Ct,
         CU_Freq = CU_Ct / (Lgth_Wet / 100)) %>%
  #
  mutate(Sin_CL = Sin) %>%
  # get any missing lat/longs from GAA data
  left_join(gaa_locs) %>%
  mutate(LON_DD = if_else(is.na(LON_DD), Lon, LON_DD),
         LAT_DD = if_else(is.na(LAT_DD), Lat, LAT_DD)) %>%
  select(-Lon, -Lat)

champ_cu = chunitDf

# calculate average habitat data across all years
champ_site_2011_17_avg = champ_site_2011_17 %>%
  filter(VisitObjective == 'Primary Visit',
         VisitStatus == 'Released to Public') %>%
  select(-(`Metric #`:GenerationDate),
         -RS_name,
         -Geo_Cond) %>%
  group_by(Watershed, Site) %>%
  summarise_at(vars(LAT_DD,
                    LON_DD,
                    SlowWater_Area:CU_Freq,
                    Sin_CL),
               list(median),
               na.rm = T) %>%
  ungroup() %>%
  left_join(champ_site_2011_17 %>%
              filter(VisitObjective == 'Primary Visit',
                     VisitStatus == 'Released to Public') %>%
              select(Watershed, Site,
                     # Category:SideChannel,
                     x_albers:y_albers,
                     Stream:MeanU,
                     Geo_Cond) %>%
              distinct() %>%
              arrange(Watershed, Site) %>%
              gather(metric, value, -Watershed, -Site) %>%
              filter(!is.na(value)) %>%
              distinct() %>%
              spread(metric, value, fill = NA) %>%
              distinct() %>%
              mutate_at(vars(CEC_L1, CEC_L2,
                             CUMDRAINAG, DistPrin1,
                             Elev_M, 
                             HUC4:LEVEL3_NM,
                             MeanU,
                             NatPrin1:NatPrin2,
                             Ppt:Strah,
                             x_albers:y_albers),
                        list(as.numeric))) %>%
  mutate(VisitObjective = 'Primary Visit',
         VisitStatus = 'Released to Public',
         VisitYear = 'All') %>%
  select(one_of(names(champ_site_2011_17))) %>%
  mutate_at(vars(Site, Watershed),
            list(fct_explicit_na))

# updated habitat dictionary
hab_dict_2017 = read_csv('data/raw/habitat/CHaMP_FinalMetrics_20180308/Definitions.csv') %>%
  select(ShortName, Name, MetricEngineName, MetricGroupName, DescriptiveText, UnitOfMeasure, UnitOfMeasureAbbrv) %>%
  distinct() %>%
  left_join(hab_catg %>%
              select(ShortName, MetricCategory)) %>%
  bind_rows(hab_dict_2014 %>%
              filter(is.na(MetricEngineName))) %>%
  # add some temperature metrics from NorWeST
  bind_rows(tibble(ShortName = c('aug_temp',
                                 'avg_aug_temp'),
                   Name = c('August Temperature',
                            'Avg. August Temperature'),
                   MetricEngineName = 'NorWeST',
                   MetricGroupName = 'Visit Metric',
                   DescriptiveText = c('Average predicted daily August temperature from NorWest for a particular year.',
                                       'Average predicted daily August temperature from NorWest, averaged across the years 2002-2011.'),
                   UnitOfMeasure = 'Degree (Celsius)',
                   UnitOfMeasureAbbrv = "°C",
                   MetricCategory = 'Temperature'))

use_data(champ_site_2011_17, champ_site_2011_17_avg, champ_cu, hab_dict_2017,
         overwrite = T,
         version = 2)

#-----------------------------------------------------------------
# DASH metrics at CHaMP sites
# covers 2014-2017 (after CHaMP protocol was stabalized)
# Richie re-calculated these from CHaMP measurements, following the DASH methods
#-----------------------------------------------------------------
data("champ_site_2011_17")

champ_dash = read_csv('data/raw/habitat/CHaMP_DASH/ChaMP_Dash_Met.csv') %>%
  select(-starts_with('X')) %>%
  rename(Ucut_Area = UcutArea,
         Sin_CL = Sin) %>%
  # add some info from CHaMP
  left_join(champ_site_2011_17 %>%
              select(VisitID, 
                     Panel,
                     Protocol,
                     Crew,
                     Stream,
                     VisitObjective,
                     VisitStatus,
                     Elev_M,
                     OwnerType:HUC6,
                     Ppt,
                     NatClass,
                     DistClass,
                     FstNT_Area,
                     Geo_Cond)) %>%
  select(one_of(names(champ_site_2011_17)),
         everything()) %>%
  select(Watershed, Site, SampleDate, 
         VisitID, Panel, VisitYear,
         everything())
  
# filter out some sites with no DASH metrics attached to them
# data.frame with how many DASH metrics were computed
n_dash_mets = champ_dash %>%
  select(Site, Watershed, VisitID, VisitYear) %>%
  bind_cols(champ_dash %>%
              select(SlowWater_Area:LWcnt_Wet,
                     -Geo_Cond) %>%
              transmute(n_NA = rowSums(is.na(.)))) %>%
  arrange(desc(n_NA))

xtabs(~ Watershed + VisitYear + (n_NA > 50), 
      n_dash_mets) %>%
  addmargins()

# champ_dash %<>%
#   anti_join(n_dash_mets %>%
#               filter(n_dash_mets < 50))

names(champ_site_2011_17)[!names(champ_site_2011_17) %in% names(champ_dash)] %>%
  sort()

# average metrics across years for each site
champ_dash_avg = champ_dash %>%
  filter(VisitObjective == 'Primary Visit',
         VisitStatus == 'Released to Public') %>%
  select(-Geo_Cond) %>%
  group_by(Watershed, Site) %>%
  summarise_at(vars(LAT_DD,
                    LON_DD,
                    SlowWater_Area:CU_Freq,
                    Sin_CL:LWcnt_Wet),
               list(median),
               na.rm = T) %>%
  ungroup() %>%
  left_join(champ_dash %>%
              filter(VisitObjective == 'Primary Visit',
                     VisitStatus == 'Released to Public') %>%
              select(Watershed, Site,
                     Stream:MeanU,
                     Geo_Cond) %>%
              distinct() %>%
              arrange(Watershed, Site) %>%
              gather(metric, value, -Watershed, -Site) %>%
              filter(!is.na(value)) %>%
              distinct() %>%
              spread(metric, value, fill = NA) %>%
              distinct() %>%
              mutate_at(vars(CUMDRAINAG, DistPrin1,
                             Elev_M, 
                             HUC4:HUC6,
                             MeanU,
                             NatPrin1:NatPrin2,
                             Ppt:Strah),
                        list(as.numeric))) %>%
  mutate(VisitObjective = 'Primary Visit',
         VisitStatus = 'Released to Public',
         VisitYear = 'All') %>%
  select(one_of(names(champ_dash))) %>%
  mutate_at(vars(Site, Watershed),
            list(fct_explicit_na))

n_dash_mets %>%
  anti_join(champ_dash_avg %>%
              select(-VisitYear)) %>%
  arrange(n_NA)


use_data(champ_dash, champ_dash_avg,
         overwrite = T,
         version = 2)
